{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facial-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #filters out annoying warnings in PCA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compatible-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "from utility_functions import load_file, pickle_file, starting_run, finished_run\n",
    "from analysis_variables import logreg_targets, de_col_keys, de_col_values, outcome_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "directed-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = load_file(\"summary_costs_enhanced.pickle\")\n",
    "category_status = load_file(\"category_status_filtered.pickle\")\n",
    "pca = PCA(n_components=10)\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "mScaler = MinMaxScaler()\n",
    "if not os.path.isdir(f\"../tables/logreg\"):\n",
    "    os.mkdir(f\"../tables/logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nonprofit-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_cols = ['marital_status', 'initial_discharge_quarter', 'gender', 'race', 'payer']\n",
    "def encode_dataset(dataset):\n",
    "    encoded_dataset = pd.DataFrame(\n",
    "        enc.fit_transform(dataset), dataset.index\n",
    "    )\n",
    "    encoded_dataset.columns = enc.get_feature_names(dataset.columns)\n",
    "    return encoded_dataset\n",
    "def preprocess_dataset(dataset):\n",
    "    #encode dataset demographics\n",
    "    dem_dataset = dataset.loc[:, demographic_cols].dropna()\n",
    "    encoded_dataset = encode_dataset(dem_dataset).join(dataset[\"age\"], how='inner').join(category_status, how=\"inner\")\n",
    "    #scale columns\n",
    "    scaled_data = pd.DataFrame(\n",
    "        scaler.fit_transform(encoded_dataset),\n",
    "        index = encoded_dataset.index,\n",
    "        columns = encoded_dataset.columns\n",
    "    )\n",
    "    pca_data = pd.DataFrame(\n",
    "        mScaler.fit_transform(encoded_dataset),\n",
    "        index = encoded_dataset.index,\n",
    "        columns = encoded_dataset.columns\n",
    "    )\n",
    "    return scaled_data, pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg(dataset, target):\n",
    "    return Logit(target, dataset).fit_regularized(maxiter=1000, disp=False).summary2().tables[1].sort_values(['P>|z|', 'Coef.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "threatened-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PCA(dataset):\n",
    "    print(dataset.shape)\n",
    "    fitted_model = pca.fit(dataset)\n",
    "    return pd.DataFrame(scaler.fit_transform(fitted_model.transform(dataset)), index=dataset.index), fitted_model.explained_variance_ratio_, pd.DataFrame(fitted_model.components_.T, index=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "approximate-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(target):\n",
    "    dataset = filtered_data.join(target.rename(\"target\"), how=\"inner\")\n",
    "    stats = pd.DataFrame({\n",
    "        'Metric': outcome_cols,\n",
    "        'Mean True': [dataset.loc[dataset[\"target\"] == True][col].mean() for col in outcome_cols],\n",
    "        'Mean False': [dataset.loc[dataset[\"target\"] == False][col].mean() for col in outcome_cols],\n",
    "        'P value': [\n",
    "            ttest_ind(\n",
    "                dataset.loc[dataset[\"target\"] == True][col],\n",
    "                dataset.loc[dataset[\"target\"] == False][col],\n",
    "                equal_var=False\n",
    "            ).pvalue*2 for col in outcome_cols\n",
    "        ]\n",
    "    })\n",
    "    print(stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mechanical-prime",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Full 11:49:06.049733\n",
      "(5547, 33)\n",
      "Starting Immediate Cholecystectomy vs Others for Complicated Colic 11:49:06.150673\n",
      "True     3528\n",
      "False    1250\n",
      "Name: Cholecystectomy Type, dtype: int64\n",
      "                   Metric     Mean True   Mean False       P value\n",
      "0                    Cost  10795.296551  9093.553402  2.665395e-09\n",
      "1  Inpatient Readmissions      0.011054     0.140000  4.647595e-32\n",
      "2         ED Readmissions      0.011905     0.088000  2.825065e-18\n",
      "3                    Died      0.000000     0.000800  6.350084e-01\n",
      "\n",
      "\n",
      "Starting Discharge vs Admission for Uncomplicated Colic 11:49:06.319733\n",
      "False    495\n",
      "True     274\n",
      "Name: Admission Status, dtype: int64\n",
      "                   Metric   Mean True   Mean False        P value\n",
      "0                    Cost  969.160782  9597.609460  1.440181e-111\n",
      "1  Inpatient Readmissions    0.007299     0.028283   6.971070e-02\n",
      "2         ED Readmissions    0.018248     0.014141   1.435143e+00\n",
      "3                    Died    0.000000     0.000000            NaN\n",
      "\n",
      "\n",
      "Starting Given Discharge and Uncomplicated Colic - No Surgery vs Others 11:49:06.441575\n",
      "True     221\n",
      "False     53\n",
      "Name: Cholecystectomy Type, dtype: int64\n",
      "                   Metric   Mean True   Mean False       P value\n",
      "0                    Cost  816.777169  1604.571694  1.570049e-07\n",
      "1  Inpatient Readmissions    0.000000     0.037736  3.185347e-01\n",
      "2         ED Readmissions    0.004525     0.075472  2.529201e-01\n",
      "3                    Died    0.000000     0.000000           NaN\n",
      "\n",
      "\n",
      "Starting Given Admission and Uncomplicated Colic - Immediate Surgery vs Others 11:49:06.588693\n",
      "False    380\n",
      "True     115\n",
      "Name: Cholecystectomy Type, dtype: int64\n",
      "                   Metric     Mean True   Mean False   P value\n",
      "0                    Cost  12045.085204  8856.926012  0.000057\n",
      "1  Inpatient Readmissions      0.000000     0.036842  0.001818\n",
      "2         ED Readmissions      0.000000     0.018421  0.038865\n",
      "3                    Died      0.000000     0.000000       NaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Full\": filtered_data,\n",
    "#     \"Inflamed\": filtered_data.loc[category_status[\"has biliary colic with inflammation\"].eq(1)],\n",
    "#     \"Uninflamed\": filtered_data.loc[category_status[\"has biliary colic with inflammation\"].eq(0)]\n",
    "}\n",
    "explained_variance = {}\n",
    "ttest_results = []\n",
    "for name, dataset in datasets.items():\n",
    "    starting_run(name)\n",
    "    scaled_data, pca_data = preprocess_dataset(dataset)\n",
    "    pca_dataset, component_importance, component_eigenvalues = run_PCA(pca_data)\n",
    "    dataset = dataset.loc[scaled_data.index]\n",
    "    explained_variance[name] = component_importance\n",
    "#     if name != \"Full\":\n",
    "#         del scaled_data[\"has biliary colic with inflammation\"]\n",
    "    for target_name, target_function in logreg_targets.items():\n",
    "        starting_run(target_name)\n",
    "        target_data = target_function(dataset)\n",
    "        print(target_data.value_counts())\n",
    "        run_logreg(scaled_data.loc[target_data.index], target_data).to_csv(f\"../tables/logreg/{target_name} Feature Scores.csv\")\n",
    "        run_logreg(pca_dataset.loc[target_data.index], target_data).to_csv(f\"../tables/logreg/{target_name} PCA Component Scores.csv\")\n",
    "        ttest_results.append(ttest(target_data))\n",
    "        print()\n",
    "        print()\n",
    "    component_eigenvalues.to_csv(f\"../tables/logreg/PCA eigenvalues.csv\")\n",
    "#     pickle_file(f\"{name}_logreg_targets.pickle\", targets)\n",
    "pd.DataFrame(explained_variance).to_csv(f\"../tables/logreg/PCA explained variance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
