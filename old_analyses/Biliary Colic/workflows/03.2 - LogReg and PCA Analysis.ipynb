{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46289bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #filters out annoying warnings in PCA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc084b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from scipy.stats import ttest_ind, f_oneway, norm, sem, chisquare\n",
    "from utility_functions import load_file, starting_run, print_to_drop, evaluate_model\n",
    "from analysis_variables import logreg_targets, de_col_keys, de_col_values, outcome_cols, code_category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ac332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_file(\"summary_costs_enhanced.pickle\")\n",
    "category_status = load_file(\"comorbidities.pickle\")\n",
    "pca = PCA(n_components=10)\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "mScaler = MinMaxScaler()\n",
    "if not os.path.isdir(f\"../tables/logreg\"):\n",
    "    os.mkdir(f\"../tables/logreg\")\n",
    "if not os.path.isdir(f\"../tables/ttest\"):\n",
    "    os.mkdir(f\"../tables/ttest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c780463",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_cols = ['marital_status', 'initial_discharge_quarter', 'gender', 'race', 'payer']\n",
    "numerical_demographic_cols = ['age', 'median_zip_income', 'CMDF CCI']\n",
    "def encode_dataset(dataset):\n",
    "    encoded_dataset = pd.DataFrame(\n",
    "        enc.fit_transform(dataset), dataset.index\n",
    "    )\n",
    "    encoded_dataset.columns = enc.get_feature_names(dataset.columns)\n",
    "    return encoded_dataset\n",
    "def preprocess_dataset(dataset):\n",
    "    #encode dataset demographics\n",
    "    dem_dataset = dataset.loc[:, demographic_cols].dropna()\n",
    "    encoded_dataset = encode_dataset(dem_dataset).join(dataset[numerical_demographic_cols], how='inner')\\\n",
    "        .join(category_status.loc[:, list(code_category_dict.keys())[20:]], how=\"inner\")\n",
    "    outer_encoded_dataset = encode_dataset(dem_dataset).join(dataset[numerical_demographic_cols], how='outer')\\\n",
    "        .join(category_status.loc[:, list(code_category_dict.keys())[20:]], how=\"outer\") # only computed to find dropped row number.\n",
    "    print_to_drop(f\"Dropped {outer_encoded_dataset.shape[0] - encoded_dataset.shape[0]} rows for 3.2 analysis due to missing demographics.\")\n",
    "    #scale columns\n",
    "    scaled_data = pd.DataFrame(\n",
    "        scaler.fit_transform(encoded_dataset),\n",
    "        index = encoded_dataset.index,\n",
    "        columns = encoded_dataset.columns\n",
    "    )\n",
    "    pca_data = pd.DataFrame(\n",
    "        mScaler.fit_transform(encoded_dataset),\n",
    "        index = encoded_dataset.index,\n",
    "        columns = encoded_dataset.columns\n",
    "    )\n",
    "    return scaled_data, pca_data, encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17f8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg(dataset, target, print_output_file):\n",
    "    # Calculations:\n",
    "    logit_model = Logit(target, dataset).fit_regularized(maxiter=1000, disp=False)\n",
    "    summary = logit_model.summary2().tables[1].sort_values(['P>|z|', 'Coef.'])\n",
    "    summary[\"OR\"] = summary['Coef.'].transform(np.exp)\n",
    "    summary[\"OR CI\"] = [norm.interval(alpha=0.95, loc=0, scale=item[1])[1] for item in summary['Std.Err.'].iteritems()]\n",
    "    summary[\"OR Formatted\"] = summary.apply(\n",
    "        lambda row: f\"{round(row['OR'], 2)} ({round(row['OR']-row['OR CI'], 2)}, {round(row['OR']+row['OR CI'], 2)})\",\n",
    "        axis=1\n",
    "    )\n",
    "    # Cleaning up summary output cols:\n",
    "    summary[\"Odds Ratio of ____ (95% CI)\"] = summary[\"OR Formatted\"]\n",
    "    summary[\"P-value\"] = summary[\"P>|z|\"]\n",
    "    output_summary = summary[[\"Odds Ratio of ____ (95% CI)\", \"P-value\"]].round(5).applymap(\n",
    "        lambda cell: \"< 0.00001\" if cell == 0.0 else cell\n",
    "    )\n",
    "    # Model eval printing:\n",
    "    for line in evaluate_model(target, logit_model.predict(dataset), len(dataset.columns)):\n",
    "        print_output_file.write(line + \" \\n\")\n",
    "    print_output_file.write(f\"Numer of Groups: {len(dataset.columns)} \\n\")\n",
    "    return output_summary, pd.DataFrame({\n",
    "        \"predicted\": logit_model.predict(dataset),\n",
    "        \"expected\": target.astype(\"int\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e741814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PCA(dataset):\n",
    "    print(dataset.shape)\n",
    "    fitted_model = pca.fit(dataset)\n",
    "    return pd.DataFrame(\n",
    "        scaler.fit_transform(fitted_model.transform(dataset)), index=dataset.index\n",
    "    ), fitted_model.explained_variance_ratio_, pd.DataFrame(fitted_model.components_.T, index=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "242bac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(target):\n",
    "    def ci(col, is_true, dataset):\n",
    "        if col[\"type\"] == \"string\":\n",
    "            dataset[col[\"name\"]] = dataset[col[\"name\"]].map({col[\"positive_class\"]: 1}).fillna(0)\n",
    "        mean, sem = dataset.loc[dataset[\"target\"] == is_true][col[\"name\"]].agg([\"mean\", \"sem\"])\n",
    "        return f\"{round(mean, 4)} Â± {round(norm.interval(alpha=0.95,loc=0,scale=sem)[1], 4)}\"\n",
    "    dataset = data.join(target.rename(\"target\"), how=\"inner\")\n",
    "    stats = pd.DataFrame({\n",
    "        'Metric': [col[\"name\"] for col in outcome_cols],\n",
    "        'Mean True': [ci(col, True, dataset) for col in outcome_cols],\n",
    "        'Mean False': [ci(col, False, dataset) for col in outcome_cols],\n",
    "        'P value': [\n",
    "            ttest_ind(\n",
    "                dataset.loc[dataset[\"target\"] == True][col[\"name\"]],\n",
    "                dataset.loc[dataset[\"target\"] == False][col[\"name\"]],\n",
    "                equal_var=False\n",
    "            ).pvalue*2 for col in outcome_cols\n",
    "        ]\n",
    "    })\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27894e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LogReg 17:38:17.365903\n",
      "(15532, 35)\n",
      "Starting Complicated Colic - Given Admission - Immediate Cholecystectomy vs Others 17:38:17.951025\n",
      "Starting Complicated Colic - Given Admission - Delayed Cholecystectomy vs None 17:38:19.017261\n",
      "Starting Complicated Colic - Given Admission - Delayed Cholecystectomy vs Delayed Emergency 17:38:20.180138\n",
      "Starting Complicated Colic - Given Discharge - No Surgery vs Others 17:38:21.475727\n",
      "Starting Complicated Colic - Given Discharge - Delayed Surgery vs Delayed Emergency 17:38:22.126756\n",
      "Starting Complicated Colic - Discharge vs Admission 17:38:22.958103\n",
      "Starting Uncomplicated Colic - Discharge vs Admission 17:38:23.632290\n",
      "Starting Uncomplicated Colic - Given Discharge - No Surgery vs Others 17:38:24.317885\n",
      "Starting Uncomplicated Colic - Given Admission - Immediate Surgery vs Others 17:38:24.973866\n",
      "Starting Uncomplicated Colic - Given Admission - Delayed Surgery vs No Surgery 17:38:25.537275\n"
     ]
    }
   ],
   "source": [
    "starting_run(\"LogReg\")\n",
    "scaled_data, pca_data, encoded_dataset = preprocess_dataset(data)\n",
    "pca_dataset, component_importance, component_eigenvalues = run_PCA(pca_data)\n",
    "data = data.loc[scaled_data.index]\n",
    "for target_name, target_function in logreg_targets.items():\n",
    "    starting_run(target_name)\n",
    "    with open(f\"../tables/ttest/{target_name}.txt\", 'w') as f:\n",
    "        target_data = target_function(data)\n",
    "        f.write(target_name + \" \\n\")\n",
    "        f.write(target_data.value_counts().to_string() + \" \\n\")\n",
    "        f.write(\"Logreg Results: \\n\")\n",
    "        summary, model_eval = run_logreg(scaled_data.loc[target_data.index], target_data, f)\n",
    "        summary.to_csv(f\"../tables/logreg/{target_name} Feature Scores.csv\")\n",
    "        model_eval.to_csv(f\"../tables/logreg/Model Eval {target_name} Feature Scores.csv\")\n",
    "        f.write(\"PCA Results: \\n\")\n",
    "        run_logreg(pca_dataset.loc[target_data.index], target_data, f)[0].to_csv(f\"../tables/logreg/{target_name} PCA Component Scores.csv\")\n",
    "        f.write(ttest(target_data).to_string())\n",
    "component_eigenvalues.to_csv(f\"../tables/logreg/PCA eigenvalues.csv\")\n",
    "pd.DataFrame(component_importance).to_csv(f\"../tables/logreg/PCA explained variance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807080a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complicated 0.0\n",
      "Uncomplicated 0.0\n"
     ]
    }
   ],
   "source": [
    "for val in de_col_values[de_col_keys[1]]:\n",
    "    full_data = data.join(category_status).query(f\"`{de_col_keys[1]}` == '{val}'\")\n",
    "    print(val, chisquare(\n",
    "        full_data.groupby(['Obesity', 'Mood Disorders'])['initial_record_id'].count(),\n",
    "        list(full_data.groupby('Obesity')['initial_record_id'].count()/2)*2\n",
    "    )[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c566008867b8984604745a2c8b464c8cbb3b13ca4eb03c09ef659d8b6959cc99"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('HCUP-study-figs': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
